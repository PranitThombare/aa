{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Evolving technology continuously reshapes our world, pushing boundaries and unlocking new possibilities. From the rapid advancements in artificial intelligence and machine learning that augment our capabilities, to the transformative potential of quantum computing and biotechnology, innovation propels us forward. Each breakthrough in connectivity, like 5 G networks, fuels global integration and communication. Smart devices and the Internet of Things (IoT) intertwine with everyday life, enhancing efficiency and convenience. As technology evolves, it not only accelerates progress but also challenges us to navigate its ethical and societal implications, shaping the future we collectively forge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'evolving technology continuously reshapes our world, pushing boundaries and unlocking new possibilities. from the rapid advancements in artificial intelligence and machine learning that augment our capabilities, to the transformative potential of quantum computing and biotechnology, innovation propels us forward. each breakthrough in connectivity, like 5 g networks, fuels global integration and communication. smart devices and the internet of things (iot) intertwine with everyday life, enhancing efficiency and convenience. as technology evolves, it not only accelerates progress but also challenges us to navigate its ethical and societal implications, shaping the future we collectively forge.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtok = word_tokenize(text)\n",
    "stok = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer('english')\n",
    "port = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_word = []\n",
    "p_word = []\n",
    "for i in wtok:\n",
    "    s_word.append(snowball.stem(i))\n",
    "    p_word.append(port.stem(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evolv',\n",
       " 'technolog',\n",
       " 'continu',\n",
       " 'reshap',\n",
       " 'our',\n",
       " 'world',\n",
       " ',',\n",
       " 'push',\n",
       " 'boundari',\n",
       " 'and',\n",
       " 'unlock',\n",
       " 'new',\n",
       " 'possibl',\n",
       " '.',\n",
       " 'from',\n",
       " 'the',\n",
       " 'rapid',\n",
       " 'advanc',\n",
       " 'in',\n",
       " 'artifici',\n",
       " 'intellig',\n",
       " 'and',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'that',\n",
       " 'augment',\n",
       " 'our',\n",
       " 'capabl',\n",
       " ',',\n",
       " 'to',\n",
       " 'the',\n",
       " 'transform',\n",
       " 'potenti',\n",
       " 'of',\n",
       " 'quantum',\n",
       " 'comput',\n",
       " 'and',\n",
       " 'biotechnolog',\n",
       " ',',\n",
       " 'innov',\n",
       " 'propel',\n",
       " 'us',\n",
       " 'forward',\n",
       " '.',\n",
       " 'each',\n",
       " 'breakthrough',\n",
       " 'in',\n",
       " 'connect',\n",
       " ',',\n",
       " 'like',\n",
       " '5',\n",
       " 'g',\n",
       " 'network',\n",
       " ',',\n",
       " 'fuel',\n",
       " 'global',\n",
       " 'integr',\n",
       " 'and',\n",
       " 'communic',\n",
       " '.',\n",
       " 'smart',\n",
       " 'devic',\n",
       " 'and',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'of',\n",
       " 'thing',\n",
       " '(',\n",
       " 'iot',\n",
       " ')',\n",
       " 'intertwin',\n",
       " 'with',\n",
       " 'everyday',\n",
       " 'life',\n",
       " ',',\n",
       " 'enhanc',\n",
       " 'effici',\n",
       " 'and',\n",
       " 'conveni',\n",
       " '.',\n",
       " 'as',\n",
       " 'technolog',\n",
       " 'evolv',\n",
       " ',',\n",
       " 'it',\n",
       " 'not',\n",
       " 'onli',\n",
       " 'acceler',\n",
       " 'progress',\n",
       " 'but',\n",
       " 'also',\n",
       " 'challeng',\n",
       " 'us',\n",
       " 'to',\n",
       " 'navig',\n",
       " 'it',\n",
       " 'ethic',\n",
       " 'and',\n",
       " 'societ',\n",
       " 'implic',\n",
       " ',',\n",
       " 'shape',\n",
       " 'the',\n",
       " 'futur',\n",
       " 'we',\n",
       " 'collect',\n",
       " 'forg',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = []\n",
    "for i in s_word:\n",
    "    l = wnet.lemmatize(i)\n",
    "    lem.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evolv',\n",
       " 'technolog',\n",
       " 'continu',\n",
       " 'reshap',\n",
       " 'our',\n",
       " 'world',\n",
       " ',',\n",
       " 'push',\n",
       " 'boundari',\n",
       " 'and',\n",
       " 'unlock',\n",
       " 'new',\n",
       " 'possibl',\n",
       " '.',\n",
       " 'from',\n",
       " 'the',\n",
       " 'rapid',\n",
       " 'advanc',\n",
       " 'in',\n",
       " 'artifici',\n",
       " 'intellig',\n",
       " 'and',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'that',\n",
       " 'augment',\n",
       " 'our',\n",
       " 'capabl',\n",
       " ',',\n",
       " 'to',\n",
       " 'the',\n",
       " 'transform',\n",
       " 'potenti',\n",
       " 'of',\n",
       " 'quantum',\n",
       " 'comput',\n",
       " 'and',\n",
       " 'biotechnolog',\n",
       " ',',\n",
       " 'innov',\n",
       " 'propel',\n",
       " 'u',\n",
       " 'forward',\n",
       " '.',\n",
       " 'each',\n",
       " 'breakthrough',\n",
       " 'in',\n",
       " 'connect',\n",
       " ',',\n",
       " 'like',\n",
       " '5',\n",
       " 'g',\n",
       " 'network',\n",
       " ',',\n",
       " 'fuel',\n",
       " 'global',\n",
       " 'integr',\n",
       " 'and',\n",
       " 'communic',\n",
       " '.',\n",
       " 'smart',\n",
       " 'devic',\n",
       " 'and',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'of',\n",
       " 'thing',\n",
       " '(',\n",
       " 'iot',\n",
       " ')',\n",
       " 'intertwin',\n",
       " 'with',\n",
       " 'everyday',\n",
       " 'life',\n",
       " ',',\n",
       " 'enhanc',\n",
       " 'effici',\n",
       " 'and',\n",
       " 'conveni',\n",
       " '.',\n",
       " 'a',\n",
       " 'technolog',\n",
       " 'evolv',\n",
       " ',',\n",
       " 'it',\n",
       " 'not',\n",
       " 'onli',\n",
       " 'acceler',\n",
       " 'progress',\n",
       " 'but',\n",
       " 'also',\n",
       " 'challeng',\n",
       " 'u',\n",
       " 'to',\n",
       " 'navig',\n",
       " 'it',\n",
       " 'ethic',\n",
       " 'and',\n",
       " 'societ',\n",
       " 'implic',\n",
       " ',',\n",
       " 'shape',\n",
       " 'the',\n",
       " 'futur',\n",
       " 'we',\n",
       " 'collect',\n",
       " 'forg',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punch\n",
    "w_punc = []\n",
    "for i in lem:\n",
    "    if i.isalpha():\n",
    "        w_punc.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evolv',\n",
       " 'technolog',\n",
       " 'continu',\n",
       " 'reshap',\n",
       " 'our',\n",
       " 'world',\n",
       " 'push',\n",
       " 'boundari',\n",
       " 'and',\n",
       " 'unlock',\n",
       " 'new',\n",
       " 'possibl',\n",
       " 'from',\n",
       " 'the',\n",
       " 'rapid',\n",
       " 'advanc',\n",
       " 'in',\n",
       " 'artifici',\n",
       " 'intellig',\n",
       " 'and',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'that',\n",
       " 'augment',\n",
       " 'our',\n",
       " 'capabl',\n",
       " 'to',\n",
       " 'the',\n",
       " 'transform',\n",
       " 'potenti',\n",
       " 'of',\n",
       " 'quantum',\n",
       " 'comput',\n",
       " 'and',\n",
       " 'biotechnolog',\n",
       " 'innov',\n",
       " 'propel',\n",
       " 'u',\n",
       " 'forward',\n",
       " 'each',\n",
       " 'breakthrough',\n",
       " 'in',\n",
       " 'connect',\n",
       " 'like',\n",
       " 'g',\n",
       " 'network',\n",
       " 'fuel',\n",
       " 'global',\n",
       " 'integr',\n",
       " 'and',\n",
       " 'communic',\n",
       " 'smart',\n",
       " 'devic',\n",
       " 'and',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'of',\n",
       " 'thing',\n",
       " 'iot',\n",
       " 'intertwin',\n",
       " 'with',\n",
       " 'everyday',\n",
       " 'life',\n",
       " 'enhanc',\n",
       " 'effici',\n",
       " 'and',\n",
       " 'conveni',\n",
       " 'a',\n",
       " 'technolog',\n",
       " 'evolv',\n",
       " 'it',\n",
       " 'not',\n",
       " 'onli',\n",
       " 'acceler',\n",
       " 'progress',\n",
       " 'but',\n",
       " 'also',\n",
       " 'challeng',\n",
       " 'u',\n",
       " 'to',\n",
       " 'navig',\n",
       " 'it',\n",
       " 'ethic',\n",
       " 'and',\n",
       " 'societ',\n",
       " 'implic',\n",
       " 'shape',\n",
       " 'the',\n",
       " 'futur',\n",
       " 'we',\n",
       " 'collect',\n",
       " 'forg']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('evolv', 'JJ'), ('technolog', 'NN'), ('continu', 'NN'), ('reshap', 'VB'), ('our', 'PRP$'), ('world', 'NN'), ('push', 'NN'), ('boundari', 'NN'), ('and', 'CC'), ('unlock', 'JJ'), ('new', 'JJ'), ('possibl', 'NN'), ('from', 'IN'), ('the', 'DT'), ('rapid', 'JJ'), ('advanc', 'NN'), ('in', 'IN'), ('artifici', 'JJ'), ('intellig', 'NN'), ('and', 'CC'), ('machin', 'NN'), ('learn', 'VBP'), ('that', 'IN'), ('augment', 'JJ'), ('our', 'PRP$'), ('capabl', 'NN'), ('to', 'TO'), ('the', 'DT'), ('transform', 'NN'), ('potenti', 'NN'), ('of', 'IN'), ('quantum', 'NN'), ('comput', 'NN'), ('and', 'CC'), ('biotechnolog', 'NN'), ('innov', 'NN'), ('propel', 'VB'), ('u', 'JJ'), ('forward', 'RB'), ('each', 'DT'), ('breakthrough', 'NN'), ('in', 'IN'), ('connect', 'NN'), ('like', 'IN'), ('g', 'NN'), ('network', 'NN'), ('fuel', 'NN'), ('global', 'JJ'), ('integr', 'NN'), ('and', 'CC'), ('communic', 'JJ'), ('smart', 'JJ'), ('devic', 'NN'), ('and', 'CC'), ('the', 'DT'), ('internet', 'NN'), ('of', 'IN'), ('thing', 'NN'), ('iot', 'NN'), ('intertwin', 'NN'), ('with', 'IN'), ('everyday', 'JJ'), ('life', 'NN'), ('enhanc', 'NN'), ('effici', 'NN'), ('and', 'CC'), ('conveni', 'VB'), ('a', 'DT'), ('technolog', 'NN'), ('evolv', 'NN'), ('it', 'PRP'), ('not', 'RB'), ('onli', 'VBZ'), ('acceler', 'JJ'), ('progress', 'NN'), ('but', 'CC'), ('also', 'RB'), ('challeng', 'VBP'), ('u', 'JJ'), ('to', 'TO'), ('navig', 'VB'), ('it', 'PRP'), ('ethic', 'JJ'), ('and', 'CC'), ('societ', 'JJ'), ('implic', 'JJ'), ('shape', 'NN'), ('the', 'DT'), ('futur', 'NN'), ('we', 'PRP'), ('collect', 'VBP'), ('forg', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(w_punc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop = [ w for w in w_punc if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
